{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cbef651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully scraped and saved to top_korean_dramas100.csv.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Function to clean text (remove leading/trailing whitespaces)\n",
    "def clean_text(text):\n",
    "    return text.strip() if text else ''\n",
    "\n",
    "# Function to extract drama information from a given URL\n",
    "def extract_drama_info(url):\n",
    "    drama_data = {}\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Extracting data\n",
    "    drama_data['ID'] = clean_text(soup.find('div', class_='box-movie-adv').find('div', class_='movie-hover-title').text)\n",
    "    drama_data['Title'] = clean_text(soup.find('h1', class_='film-title').text)\n",
    "    drama_data['Genre'] = clean_text(soup.find('li', class_='show-genres').text.split(':', 1)[1])\n",
    "    drama_data['Tags'] = clean_text(soup.find('li', class_='show-tags').text.split(':', 1)[1].replace('(Vote or add tags)', ''))\n",
    "    drama_data['Synopsis'] = clean_text(soup.find('meta', {'name': 'description'})['content'])\n",
    "    drama_data['Rank'] = clean_text(soup.find('li', class_='rank').text.split(':', 1)[1])\n",
    "    drama_data['Popularity'] = clean_text(soup.find('li', class_='popularity').text.split(':', 1)[1])\n",
    "    drama_data['Score'] = clean_text(soup.find('li', class_='score').text.split(':', 1)[1])\n",
    "    drama_data['Episodes'] = clean_text(soup.find('li', class_='episodes').text.split(':', 1)[1])\n",
    "    drama_data['Duration'] = clean_text(soup.find('li', class_='duration').text.split(':', 1)[1])\n",
    "    drama_data['Watchers'] = clean_text(soup.find('span', class_='number').text)\n",
    "    drama_data['Start_date'] = clean_text(soup.find('span', class_='aired').text.split('-', 1)[0])\n",
    "    drama_data['End_date'] = clean_text(soup.find('span', class_='aired').text.split('-', 1)[1])\n",
    "    drama_data['Day_aired'] = clean_text(soup.find('span', class_='show-status').text)\n",
    "\n",
    "    # Extracting main role actors\n",
    "    main_role_actors = [clean_text(actor.text) for actor in soup.find_all('li', class_='list-item col-sm-4') if\n",
    "                        actor.find('small', class_='text-muted') and\n",
    "                        actor.find('small', class_='text-muted').text == 'Main Role']\n",
    "    drama_data['Main Role'] = ', '.join(main_role_actors)\n",
    "\n",
    "    return drama_data\n",
    "\n",
    "# Main scraping logic\n",
    "top_korean_dramas_url = 'https://mydramalist.com/shows/top_korean_dramas'\n",
    "page = requests.get(top_korean_dramas_url)\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "# Extracting drama URLs from the main page\n",
    "drama_urls = [a['href'] for a in soup.find_all('a', class_='title text-primary')]\n",
    "\n",
    "# Scraping each drama's information and storing in a list\n",
    "drama_list = []\n",
    "for drama_url in drama_urls:\n",
    "    drama_data = extract_drama_info(f'https://mydramalist.com{drama_url}')\n",
    "    drama_list.append(drama_data)\n",
    "\n",
    "# Writing data to CSV file\n",
    "csv_filename = 'top_korean_dramas100.csv'\n",
    "with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['ID', 'Title', 'Genre', 'Tags', 'Synopsis', 'Rank', 'Popularity',\n",
    "                  'Score', 'Episodes', 'Duration', 'Watchers', 'Start_date', 'End_date',\n",
    "                  'Day_aired', 'Main Role']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for drama_data in drama_list:\n",
    "        writer.writerow(drama_data)\n",
    "\n",
    "print(f'Data has been successfully scraped and saved to {csv_filename}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a4e016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
